{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec50ccd-9f49-4030-b6bc-0dfc0531bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep refreshing the env to update experiments.json\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# make cells take up the whole width to display graphs better\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93d03d-80f0-4719-886f-3345af43c1c2",
   "metadata": {},
   "source": [
    "### Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be1fe3-8070-476e-a986-be458284072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all FCN models 50 epochs\n",
    "experiment_filename = \"experiments_20250111_214659.json\"\n",
    "\n",
    "# all Transformer models 50 epochs\n",
    "# experiment_filename = \"experiments_20250112_062438.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538946ea-d07b-461e-b0e5-45599ba1c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "with open(f\"results/{experiment_filename}\", \"r\") as f:\n",
    "    loaded_data = json.load(f)\n",
    "\n",
    "\n",
    "detailed_runs = {}  # {dataset_size: [(params, best_val_loss, best_train_loss), ...]}\n",
    "for ds_size_str, runs in loaded_data.items():\n",
    "    ds_size = float(ds_size_str)\n",
    "    run_losses = []\n",
    "    for run in runs:\n",
    "        val_losses = [step_data[\"val_loss\"] for step_data in run[\"losses\"].values()]\n",
    "        train_losses = [step_data[\"train_loss\"] for step_data in run[\"losses\"].values()]\n",
    "        best_val_loss = min(val_losses)\n",
    "        best_train_loss = min(train_losses)\n",
    "        num_params = run[\"config\"][\"num_params\"]\n",
    "        run_losses.append((num_params, best_val_loss, best_train_loss))\n",
    "    detailed_runs[ds_size] = run_losses\n",
    "\n",
    "# Create summary_results for scaling law plot\n",
    "summary_val = {}  # best achievable validation loss per dataset size\n",
    "for ds_size, runs in detailed_runs.items():\n",
    "    best_val = min(l[1] for l in runs)\n",
    "    summary_val[ds_size] = best_val\n",
    "\n",
    "ds_sizes = np.array(list(summary_val.keys()))\n",
    "val_losses = np.array(list(summary_val.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cae819-8097-4fec-9802-f1da0d41b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c6275-964b-4b19-bb55-327f11b915fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41617feb-3b70-439e-8cd3-b19c16caffff",
   "metadata": {},
   "source": [
    "### Create plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a47cf-04ee-4fc5-86f2-230773454ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create Plot-1 (Scaling Law for Validation Loss)\n",
    "############################################\n",
    "fig_plot1 = go.FigureWidget()\n",
    "fig_plot1.add_trace(\n",
    "    go.Scatter(\n",
    "        x=ds_sizes, \n",
    "        y=val_losses, \n",
    "        mode='lines+markers', \n",
    "        name='Best Val Loss'\n",
    "    )\n",
    ")\n",
    "# # Baselines for Validation Loss\n",
    "# fig_plot1.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=ds_sizes, \n",
    "#         y=[314.503]*len(ds_sizes),\n",
    "#         mode='lines',\n",
    "#         name='Naive Zero',\n",
    "#         line=dict(dash='dot', color='#DDD5C7')\n",
    "#     )\n",
    "# )\n",
    "# fig_plot1.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=ds_sizes, \n",
    "#         y=[101.496]*len(ds_sizes),\n",
    "#         mode='lines',\n",
    "#         name='Naive Mean',\n",
    "#         line=dict(dash='dot', color='#3B7EA1')\n",
    "#     )\n",
    "# )\n",
    "# fig_plot1.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=ds_sizes, \n",
    "#         y=[100.102]*len(ds_sizes),\n",
    "#         mode='lines',\n",
    "#         name='Naive k=1',\n",
    "#         line=dict(dash='dot', color='#C4820E')\n",
    "#     )\n",
    "# )\n",
    "fig_plot1.update_layout(\n",
    "    title=\"Scaling Law: Validation Loss vs Dataset Size\",\n",
    "    xaxis_title=\"Dataset Size\",\n",
    "    yaxis_title=\"Validation Loss\",\n",
    "    template=\"plotly_white\",\n",
    "    width=900,\n",
    "    height=600\n",
    ")\n",
    "# Add buttons for toggling axis scales (reuse same layout as before)\n",
    "xaxis_buttons = [\n",
    "    dict(args=[{\"xaxis.type\": \"linear\"}], label=\"X-Linear\", method=\"relayout\"),\n",
    "    dict(args=[{\"xaxis.type\": \"log\"}], label=\"X-Log\", method=\"relayout\")\n",
    "]\n",
    "yaxis_buttons = [\n",
    "    dict(args=[{\"yaxis.type\": \"linear\"}], label=\"Y-Linear\", method=\"relayout\"),\n",
    "    dict(args=[{\"yaxis.type\": \"log\"}], label=\"Y-Log\", method=\"relayout\")\n",
    "]\n",
    "fig_plot1.update_layout(\n",
    "    margin=dict(r=150),\n",
    "    updatemenus=[\n",
    "        dict(type=\"buttons\", direction=\"up\", x=1.02, y=0.05, xanchor=\"left\", yanchor=\"bottom\",\n",
    "             showactive=True, buttons=xaxis_buttons),\n",
    "        dict(type=\"buttons\", direction=\"up\", x=1.145, y=0.05, xanchor=\"left\", yanchor=\"bottom\",\n",
    "             showactive=True, buttons=yaxis_buttons)\n",
    "    ]\n",
    ")\n",
    "\n",
    "############################################\n",
    "# Create Plot-2 (Saturation Curves for Train Loss)\n",
    "############################################\n",
    "fig_train_loss = go.FigureWidget()\n",
    "fig_train_loss.update_layout(\n",
    "    title=\"Saturation Curves: Click a point in Plot-1 to view Train Loss curves\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Training Loss\",\n",
    "    template=\"plotly_white\",\n",
    "    width=720,\n",
    "    height=480,\n",
    ")\n",
    "fig_train_loss.update_layout(\n",
    "    margin=dict(r=150),\n",
    "    updatemenus=[\n",
    "        dict(type=\"buttons\", direction=\"up\", x=1.02, y=0.05, xanchor=\"left\", yanchor=\"bottom\",\n",
    "             showactive=True, buttons=xaxis_buttons),\n",
    "        dict(type=\"buttons\", direction=\"up\", x=1.145, y=0.05, xanchor=\"left\", yanchor=\"bottom\",\n",
    "             showactive=True, buttons=yaxis_buttons)\n",
    "    ]\n",
    ")\n",
    "\n",
    "############################################\n",
    "# Create Plot-3 (Saturation Curves for Validation Loss)\n",
    "############################################\n",
    "fig_val_loss = go.FigureWidget()\n",
    "fig_val_loss.update_layout(\n",
    "    title=\"Saturation Curves: Click a point in Plot-1 to view Val Loss curves\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Validation Loss\",\n",
    "    template=\"plotly_white\",\n",
    "    width=720,\n",
    "    height=480,\n",
    ")\n",
    "fig_val_loss.update_layout(\n",
    "    margin=dict(r=150),\n",
    "    updatemenus=[\n",
    "        dict(type=\"buttons\", direction=\"up\", x=1.02, y=0.05, xanchor=\"left\", yanchor=\"bottom\",\n",
    "             showactive=True, buttons=xaxis_buttons),\n",
    "        dict(type=\"buttons\", direction=\"up\", x=1.145, y=0.05, xanchor=\"left\", yanchor=\"bottom\",\n",
    "             showactive=True, buttons=yaxis_buttons)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Callback function to update saturation curves based on clicked point in Plot-1\n",
    "def update_saturation_curves(trace, points, selector):\n",
    "    if points.point_inds:\n",
    "        idx = points.point_inds[0]\n",
    "        ds_size = ds_sizes[idx]\n",
    "        \n",
    "        fig_val_loss.data = []\n",
    "        fig_train_loss.data = []\n",
    "        \n",
    "        runs = loaded_data.get(str(int(ds_size)), [])\n",
    "        \n",
    "        for run in runs:\n",
    "            # Retrieve relevant config info\n",
    "            batch_size = run[\"config\"][\"batch_size\"]\n",
    "            dataset_size = run[\"config\"][\"dataset_size\"]  # might need str->int conversion\n",
    "            # If dataset_size is stored as float, ensure int conversion\n",
    "            dataset_size = int(dataset_size)\n",
    "\n",
    "            from math import ceil\n",
    "            # Approx number of batches per epoch\n",
    "            num_batches = ceil(dataset_size / batch_size)\n",
    "            \n",
    "            # Group the logged steps by epoch\n",
    "            epoch_dict = {}\n",
    "            for step_str, step_data in run[\"losses\"].items():\n",
    "                step_int = int(step_str)\n",
    "                epoch_idx = step_int // num_batches  # integer division\n",
    "                if epoch_idx not in epoch_dict:\n",
    "                    epoch_dict[epoch_idx] = {\"train\": [], \"val\": []}\n",
    "                epoch_dict[epoch_idx][\"train\"].append(step_data[\"train_loss\"])\n",
    "                epoch_dict[epoch_idx][\"val\"].append(step_data[\"val_loss\"])\n",
    "            \n",
    "            # Build arrays of (epoch, train_loss, val_loss) by taking the last or avg in each epoch\n",
    "            epochs = sorted(epoch_dict.keys())\n",
    "            epoch_train = []\n",
    "            epoch_val = []\n",
    "            for e in epochs:\n",
    "                # e.g. take the last logged train/val in that epoch\n",
    "                epoch_train.append(epoch_dict[e][\"train\"][-1])\n",
    "                epoch_val.append(epoch_dict[e][\"val\"][-1])\n",
    "            \n",
    "            params = run[\"config\"][\"num_params\"]\n",
    "            fig_train_loss.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=epochs,\n",
    "                    y=epoch_train,\n",
    "                    mode='lines+markers',\n",
    "                    name=f\"{params} params\"\n",
    "                )\n",
    "            )\n",
    "            fig_val_loss.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=epochs,\n",
    "                    y=epoch_val,\n",
    "                    mode='lines+markers',\n",
    "                    name=f\"{params} params\"\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        fig_train_loss.update_layout(title=f\"Train Loss Curves for Dataset Size = {int(ds_size)}\")\n",
    "        fig_val_loss.update_layout(title=f\"Val Loss Curves for Dataset Size = {int(ds_size)}\")\n",
    "\n",
    "\n",
    "# Attach the callback to the first trace (scaling law) of Plot-1\n",
    "fig_plot1.data[0].on_click(update_saturation_curves)\n",
    "\n",
    "# Arrange the plots in the desired layout\n",
    "top_row = widgets.VBox([fig_plot1])  # Scaling Law on top\n",
    "bottom_row = widgets.HBox([fig_train_loss, fig_val_loss])  # Training loss (left), Validation loss (right)\n",
    "container = widgets.VBox([top_row, bottom_row])\n",
    "\n",
    "# Display the updated layout\n",
    "display(container)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
